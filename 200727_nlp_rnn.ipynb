{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "200727-nlp_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taji99/python_basic/blob/master/200727_nlp_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2FDsgdXz7Ev",
        "colab_type": "text"
      },
      "source": [
        "# RNNによる自然言語処理\n",
        "RNNを使って、文書の自動作成を行います。  \n",
        "今回は、宮沢賢治の「銀河鉄道の夜」を学習データに使い、賢治風の文章を自動生成します。  \n",
        "文章における文字の並びを時系列データと捉えて、次の文字を予測するようにRNNを訓練します。  \n",
        "シンプルなRNN、LSTM、およびGRUの3つのRNNでそれぞれモデルを構築し、文章の生成結果を比較します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvsA4_jx1K3I",
        "colab_type": "text"
      },
      "source": [
        "## テキストデータの読み込み\n",
        "Google ドライブからテキストデータを読み込みます。  \n",
        "このノートブックと同じフォルダに、青空文庫の「銀河鉄道の夜」のテキストデータ\"gingatetsudono_yoru.txt\"を置き、パスを指定して読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkf6xcck1wEq",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "nov_dir = 'ai_master_course/Section_8/'  # フォルダへのパスを指定する\n",
        "nov_path = '/content/drive/My Drive/' + nov_dir + 'gingatetsudono_yoru.txt'\n",
        "\n",
        "# ファイルを読み込む\n",
        "with open(nov_path, 'r') as f:\n",
        "  nov_text = f.read()\n",
        "  print(nov_text[:1000])  # 最初の1000文字のみ表示"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C-l7uLVz7Ey",
        "colab_type": "text"
      },
      "source": [
        "## 正規表現による前処理\n",
        "正規表現を使って、ルビなどを除去します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OPrUpQyz7Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re  # 正規表現に必要なライブラリ\n",
        "\n",
        "text = re.sub(\"《[^》]+》\", \"\", nov_text) # ルビの削除\n",
        "text = re.sub(\"［[^］]+］\", \"\", text) # 読みの注意の削除\n",
        "text = re.sub(\"[｜ 　]\", \"\", text) # | と全角半角スペースの削除\n",
        "print(\"文字数\", len(text))  # len() で文字列の文字数も取得可能"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY7sZvcIz7E2",
        "colab_type": "text"
      },
      "source": [
        "## 各設定\n",
        "RNNの各設定です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ5ZYj61z7E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_rnn = 10  # 時系列の数\n",
        "batch_size = 128\n",
        "epochs = 60\n",
        "n_mid = 128  # 中間層のニューロン数"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhyUEeiUz7E5",
        "colab_type": "text"
      },
      "source": [
        "## 文字のベクトル化\n",
        "各文字をone-hot表現で表し、時系列の入力データおよび正解データを作成します。  \n",
        "今回はRNNの最後の時刻の出力のみ利用するので、最後の出力に対応する正解のみ必要になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwPgvftBz7E6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# インデックスと文字で辞書を作成\n",
        "chars = sorted(list(set(text)))  # setで文字の重複をなくし、各文字をリストに格納する\n",
        "print(\"文字数（重複無し）\", len(chars))\n",
        "char_indices = {}  # 文字がキーでインデックスが値\n",
        "for i, char in enumerate(chars):\n",
        "    char_indices[char] = i\n",
        "indices_char = {}  # インデックスがキーで文字が値\n",
        "for i, char in enumerate(chars):\n",
        "    indices_char[i] = char\n",
        " \n",
        "# 時系列データと、それから予測すべき文字を取り出します\n",
        "time_chars = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - n_rnn):\n",
        "    time_chars.append(text[i: i + n_rnn])\n",
        "    next_chars.append(text[i + n_rnn])\n",
        " \n",
        "# 入力と正解をone-hot表現で表します\n",
        "x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)\n",
        "t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)\n",
        "for i, t_cs in enumerate(time_chars):\n",
        "    t[i, char_indices[next_chars[i]]] = 1  # 正解をone-hot表現で表す\n",
        "    for j, char in enumerate(t_cs):\n",
        "        x[i, j, char_indices[char]] = 1  # 入力をone-hot表現で表す\n",
        "        \n",
        "print(\"xの形状\", x.shape)\n",
        "print(\"tの形状\", t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw-anpEHz7E8",
        "colab_type": "text"
      },
      "source": [
        "## モデルの構築\n",
        "SimpleRNN、LSTM、GRUの層を使ったモデルをそれぞれ構築します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7rC0ASgz7E8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
        "\n",
        "# SimpleRNN\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(SimpleRNN(n_mid, input_shape=(n_rnn, len(chars))))\n",
        "model_rnn.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model_rnn.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
        "print(model_rnn.summary())\n",
        "\n",
        "# LSTM\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))\n",
        "model_lstm.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
        "print(model_lstm.summary())\n",
        "\n",
        "# GRU\n",
        "model_gru = Sequential()\n",
        "model_gru.add(GRU(n_mid, input_shape=(n_rnn, len(chars))))\n",
        "model_gru.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
        "print(model_gru.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJANWVEJz7E-",
        "colab_type": "text"
      },
      "source": [
        "## 文書生成用の関数\n",
        "各エポックの終了後、文章を生成するための関数を記述します。  \n",
        "LambdaCallbackを使って、エポック終了時に実行される関数を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN2yJcvmz7E_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        " \n",
        "def on_epoch_end(epoch, logs):\n",
        "    print(\"エポック: \", epoch)\n",
        "\n",
        "    beta = 5  # 確率分布を調整する定数\n",
        "    prev_text = text[0:n_rnn]  # 入力に使う文字\n",
        "    created_text = prev_text  # 生成されるテキスト\n",
        "    \n",
        "    print(\"シード: \", created_text)\n",
        "\n",
        "    for i in range(400):\n",
        "        # 入力をone-hot表現に\n",
        "        x_pred = np.zeros((1, n_rnn, len(chars)))\n",
        "        for j, char in enumerate(prev_text):\n",
        "            x_pred[0, j, char_indices[char]] = 1\n",
        "        \n",
        "        # 予測を行い、次の文字を得る\n",
        "        y = model.predict(x_pred)\n",
        "        p_power = y[0] ** beta  # 確率分布の調整\n",
        "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))        \n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        created_text += next_char\n",
        "        prev_text = prev_text[1:] + next_char\n",
        "\n",
        "    print(created_text)\n",
        "    print()\n",
        "\n",
        "# エポック終了後に実行される関数を設定\n",
        "epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvDaiwJEz7FB",
        "colab_type": "text"
      },
      "source": [
        "## 学習\n",
        "構築したモデルを使って、学習を行います。  \n",
        "fit( )メソッドをではコールバックの設定をし、エポック終了後に関数が呼ばれるようにします。  \n",
        "学習には時間がかかりますので、編集→ノートブックの設定のハードウェアアクセラレーターでGPUを選択しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygj38MhQz7FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# シンプルなRNN\n",
        "model = model_rnn\n",
        "history_rnn = model_rnn.fit(x, t,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[epock_end_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XrSD7_Wt7FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM\n",
        "model = model_lstm\n",
        "history_lstm = model_lstm.fit(x, t,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[epock_end_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBD6heuXuC4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRU\n",
        "model = model_gru\n",
        "history_gru = model_gru.fit(x, t,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[epock_end_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcrTcdKlz7FD",
        "colab_type": "text"
      },
      "source": [
        "今回のケースでは、RNN < LSTM < GRUの順で文章が自然に見えます。  \n",
        "SimpleRNNでは昔の文脈を利用するのが難しいのですが、GRUではある程度利用できているようです。  \n",
        "興味のある方は、様々な条件をトライし、より自然な文章の生成にトライしてみましょう。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoPdwHq2z7FE",
        "colab_type": "text"
      },
      "source": [
        "## 学習の推移\n",
        "誤差の推移を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hajdXxYXz7FE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_rnn = history_rnn.history['loss']\n",
        "loss_lstm = history_lstm.history['loss']\n",
        "loss_gru = history_gru.history['loss']\n",
        "\n",
        "plt.plot(np.arange(len(loss_rnn)), loss_rnn, label=\"RNN\")\n",
        "plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")\n",
        "plt.plot(np.arange(len(loss_gru)), loss_gru, label=\"GRU\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3XwrsSuz7FG",
        "colab_type": "text"
      },
      "source": [
        "誤差はまだ収束していないので、さらにエポック数を重ねることにより結果は改善しそうです。  \n",
        "今回は文章の生成を行いましたが、同様にしてRNNを市場予測や自動作曲などに応用することも可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oXiPDbCw6-2",
        "colab_type": "text"
      },
      "source": [
        "## さらに自然な文章の生成のために\n",
        "さらに自然な文章生成が可能なモデルを作るために、例えば以下のようなアプローチが有効かもしれません。\n",
        "\n",
        "* **入力を単語ベクトルにする**  \n",
        "入力をone-hot表現ではなくword2vecなどの技術により作る単語ベクトルにします。  \n",
        "これにより、入力の次元数が抑えられるだけではなく、単語同士の関係性がモデルの訓練前にすでに存在することになります。    \n",
        "word2vecについては、Udemyコース「自然言語処理とチャットボット: AIによる文章生成と会話エンジン開発」で詳しく解説しています。\n",
        "\n",
        "* **コーパスをさらに大きくする**  \n",
        "一般的に、コーパスが大きいほどモデルの汎用性は高まります。  \n",
        "しかしながら、学習かかる時間が長くなるのが問題です。  \n",
        "\n",
        "* **最新のアルゴリズムを採用する**  \n",
        "自然言語処理の分野では日々新しい技術が生まれ、論文などで発表されています。  \n",
        "興味のある方は、そのような技術をモデルに取り入れてみましょう。"
      ]
    }
  ]
}