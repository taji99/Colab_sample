{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "200725-epoch_batch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taji99/python_basic/blob/master/200725_epoch_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAEuSxCItvB0",
        "colab_type": "text"
      },
      "source": [
        "# エポックとバッチ\n",
        "ニューラルネットワークの学習に大事な、エポックとバッチの概念について学んでいきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2cFoWFTtvB2",
        "colab_type": "text"
      },
      "source": [
        "## ●エポックとバッチ\n",
        "全ての訓練データを１回学習することを、1**エポック**（epoch）と数えます。  \n",
        "1エポックで、学習データを全て使い切ることになります。  \n",
        "実は、訓練データのサンプル（入力と正解のペア）は複数まとめて学習に使うのですが、このサンプルのかたまりのことを**バッチ**（batch）といいます。  \n",
        "1エポックで使用する訓練データは、複数のバッチに分割されることになります。    \n",
        "**バッチサイズ**は、このバッチに含まれるサンプル数のことです。  \n",
        "バッチ内の全てのサンプルを使用してから重みとバイアスの更新が行われるので、バッチサイズは重みとバイアスの修正を行う間隔と表現することもできます。  \n",
        "バッチサイズは、基本的に学習中ずっと一定です。  \n",
        "バッチサイズにより、学習のタイプは以降で解説する3つに分かれます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDOAwuJPtvB3",
        "colab_type": "text"
      },
      "source": [
        "## ●バッチ学習\n",
        "**バッチ学習**においては、バッチサイズが全訓練データの数になります。  \n",
        "1エポックごとに全訓練データの誤差の平均を求め、重みとバイアスを更新します。  \n",
        "一般的に学習は安定しており、他の2つの学習タイプと比較して高速ですが、局所最適解に囚われやすいのが欠点です。  \n",
        "バッチ学習における誤差は、訓練データ数をN、個々のデータの誤差を$E_i$として以下のように定義されます。\n",
        "\n",
        "$$ E = \\frac{1}{N}\\sum_{i=1}^{N} E_i $$\n",
        "  \n",
        "また、重みの勾配は次のようにして求めることができます。\n",
        "\n",
        "$$ \\frac{\\partial E}{\\partial w_{}} = \\sum_{i=1}^{N} \\frac{\\partial E_i}{\\partial w_{}}  $$\n",
        "\n",
        "重みの勾配をバッチ内の個々のデータごとに計算し、それを合計すればいいことになります。  \n",
        "この計算は、行列演算により一度で効率的に行うことができますが、具体的な方法については後ほど解説します。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zecT1Rn1tvB4",
        "colab_type": "text"
      },
      "source": [
        "## ●オンライン学習\n",
        "**オンライン学習**では、バッチサイズが1になります。  \n",
        "個々のサンプルごとに、重みとバイアスを更新されることになります。  \n",
        "個々のデータに振り回されるため安定性には欠けますが、それがかえって局所最適解に囚われることを防いでくれます。  \n",
        "このセクションで解説してきた勾配の求め方はオンライン学習のものですが、勾配をバッチ内で合計すれば他の学習タイプにも適用可能です。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blVam-9stvB5",
        "colab_type": "text"
      },
      "source": [
        "## ●ミニバッチ学習\n",
        "バッチ学習とオンライン学習の中間にあるのが**ミニバッチ学習**です。  \n",
        "訓練データを小さなかたまり（バッチ）に分割し、この小さなかたまりごとに、重みとバイアスの更新を行います。  \n",
        "バッチ学習よりもバッチのサイズが小さく、ランダムにバッチを選択するため、バッチ学習と比較して局所最適解に囚われにくいです。  \n",
        "また、オンライン学習よりもバッチサイズが大きいので、おかしな方向に学習するリスクを低減できます。  \n",
        "このように、ミニバッチ学習はバッチ学習とオンライン学習のハイブリッドです。  \n",
        "ミニバッチ学習における誤差は、ミニバッチ学習のバッチサイズを$n$（$n\\leqq N$）として以下のように定義されます。  \n",
        "\n",
        "$$ E = \\frac{1}{n}\\sum_{i=1}^{n} E_i $$\n",
        "\n",
        "また、重みの勾配は次のようにして求めることができます。\n",
        "\n",
        "$$ \\frac{\\partial E}{\\partial w_{}} = \\sum_{i=1}^{n} \\frac{\\partial E_i}{\\partial w_{}}  $$\n",
        "\n",
        "この勾配は、バッチ学習の場合と同様に行列演算を用いて一度に計算することができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-LFEXe7tvB5",
        "colab_type": "text"
      },
      "source": [
        "## ●学習の例\n",
        "例えば、訓練データのサンプル数が1000個の場合を考えましょう。  \n",
        "この1000個のサンプルを使い切ると1エポックになります。  \n",
        "バッチ学習の場合、バッチサイズは1000で、1エポックあたり1回重みとバイアスが更新されます。  \n",
        "\n",
        "一方オンライン学習の場合、バッチサイズは1で、1エポックあたり1000回更新が行われます。  \n",
        "そしてミニバッチ学習の場合、例えばバッチサイズを50に設定すると、1エポックあたり20回更新が行われます。  \n",
        "\n",
        "バッチサイズが学習時間やパフォーマンスに影響することは経験的に知られているのですが、バッチサイズを適切に設定するのはなかなか難しい問題です。  \n",
        "一般的には、10-100程度のバッチサイズを設定することが多いようです。  "
      ]
    }
  ]
}